{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T10:39:06.812892Z",
     "start_time": "2018-04-06T10:38:58.716680Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing.data import OneHotEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T10:38:58.719Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timestamp_datetime(value):\n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    value = time.localtime(value)\n",
    "    dt = time.strftime(format, value)\n",
    "    return dt\n",
    "\n",
    "\n",
    "def base_process(data):\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    print('--------------------------item---------------------------------')\n",
    "    data['len_item_category'] = data['item_category_list'].map(\n",
    "        lambda x: len(str(x).split(';')))\n",
    "    data['len_item_property'] = data['item_property_list'].map(\n",
    "        lambda x: len(str(x).split(';')))\n",
    "    for i in range(1, 2):\n",
    "        data['item_category_list' + str(\n",
    "            i\n",
    "        )] = lbl.fit_transform(data['item_category_list'].map(\n",
    "            lambda x: str(str(x).split(';')[i]) if len(str(x).split(';')) > i else ''\n",
    "        ))  # item_category_list的第0列全部都一样\n",
    "    for i in range(10):\n",
    "        data['item_property_list' + str(\n",
    "            i\n",
    "        )] = lbl.fit_transform(data['item_property_list'].map(\n",
    "            lambda x: str(str(x).split(';')[i]) if len(str(x).split(';')) > i else ''\n",
    "        ))\n",
    "    for col in ['item_id', 'item_brand_id', 'item_city_id']:\n",
    "        data[col] = lbl.fit_transform(data[col])\n",
    "    print('--------------------------user---------------------------------')\n",
    "    for col in ['user_id']:\n",
    "        data[col] = lbl.fit_transform(data[col])\n",
    "    print('user 0,1 feature')\n",
    "    data['gender0'] = data['user_gender_id'].apply(\n",
    "        lambda x: 1 if x == -1 else 2)\n",
    "    data['age0'] = data['user_age_level'].apply(\n",
    "        lambda x: 1 if x == 1004 | x == 1005 | x == 1006 | x == 1007 else 2)\n",
    "    data['occupation0'] = data['user_occupation_id'].apply(\n",
    "        lambda x: 1 if x == -1 | x == 2003 else 2)\n",
    "    data['star0'] = data['user_star_level'].apply(\n",
    "        lambda x: 1 if x == -1 | x == 3000 | x == 3001 else 2)\n",
    "    print(\n",
    "        '--------------------context------------------------------------------'\n",
    "    )\n",
    "    data['realtime'] = data['context_timestamp'].apply(timestamp_datetime)\n",
    "    data['realtime'] = pd.to_datetime(data['realtime'])\n",
    "    data['day'] = data['realtime'].dt.day\n",
    "    data['hour'] = data['realtime'].dt.hour\n",
    "    data['len_predict_category_property'] = data[\n",
    "        'predict_category_property'].map(lambda x: len(str(x).split(';')))\n",
    "\n",
    "    for i in range(5):\n",
    "        data['predict_category_property' + str(\n",
    "            i\n",
    "        )] = lbl.fit_transform(data['predict_category_property'].map(\n",
    "            lambda x: str(str(x).split(';')[i]) if len(str(x).split(';')) > i else ''\n",
    "        ))\n",
    "\n",
    "    print('context 0,1 feature')\n",
    "    data['context_page0'] = data['context_page_id'].apply(\n",
    "        lambda x: 1 if x == 4001 | x == 4002 | x == 4003 | x == 4004 | x == 4007 else 2\n",
    "    )\n",
    "    print('-------------------------shop------------------------')\n",
    "    for col in ['shop_id']:\n",
    "        data[col] = lbl.fit_transform(data[col])\n",
    "    data['shop_score_delivery0'] = data['shop_score_delivery'].apply(\n",
    "        lambda x: 0 if x <= 0.98 and x >= 0.96 else 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def map_hour(x):\n",
    "    if (x >= 0) & (x <= 7):\n",
    "        return 1\n",
    "    elif (x >= 13) & (x <= 18):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def deliver(x):\n",
    "    #x=round(x,6)\n",
    "    jiange = 0.1\n",
    "    for i in range(1, 20):\n",
    "        if (x >= 4.1 + jiange * (i - 1)) & (x <= 4.1 + jiange * i):\n",
    "            return i + 1\n",
    "    if x == -5:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def deliver1(x):\n",
    "    if (x >= 2) & (x <= 4):\n",
    "        return 1\n",
    "    elif (x >= 5) & (x <= 7):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def review(x):\n",
    "    # x=round(x,6)\n",
    "    jiange = 0.02\n",
    "    for i in range(1, 30):\n",
    "        if (x >= 0.714 + jiange * (i - 1)) & (x <= 0.714 + jiange * i):\n",
    "            return i + 1\n",
    "    if x == -1:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def review1(x):\n",
    "    # x=round(x,6)\n",
    "    if (x >= 2) & (x <= 12):\n",
    "        return 1\n",
    "    elif (x >= 13) & (x <= 15):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def service(x):\n",
    "    #x=round(x,6)\n",
    "    jiange = 0.1\n",
    "    for i in range(1, 20):\n",
    "        if (x >= 3.93 + jiange * (i - 1)) & (x <= 3.93 + jiange * i):\n",
    "            return i + 1\n",
    "    if x == -1:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def service1(x):\n",
    "    if (x >= 2) & (x <= 7):\n",
    "        return 1\n",
    "    elif (x >= 8) & (x <= 9):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def describe(x):\n",
    "    #x=round(x,6)\n",
    "    jiange = 0.1\n",
    "    for i in range(1, 30):\n",
    "        if (x >= 3.93 + jiange * (i - 1)) & (x <= 3.93 + jiange * i):\n",
    "            return i + 1\n",
    "    if x == -1:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def describe1(x):\n",
    "    if (x >= 2) & (x <= 8):\n",
    "        return 1\n",
    "    elif (x >= 9) & (x <= 10):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def timeMap(data):\n",
    "    data['hour_map'] = data['hour'].apply(map_hour)\n",
    "    return data\n",
    "\n",
    "\n",
    "def shop_box(data):\n",
    "    data['shop_score_delivery'] = data['shop_score_delivery'] * 5\n",
    "    data = data[data['shop_score_delivery'] != -5]\n",
    "    data['deliver_map'] = data['shop_score_delivery'].apply(deliver)\n",
    "    data['deliver_map'] = data['deliver_map'].apply(deliver1)\n",
    "    # del data['shop_score_delivery']\n",
    "    print(data.deliver_map.value_counts())\n",
    "\n",
    "    data['shop_score_service'] = data['shop_score_service'] * 5\n",
    "    data = data[data['shop_score_service'] != -5]\n",
    "    data['service_map'] = data['shop_score_service'].apply(service)\n",
    "    data['service_map'] = data['service_map'].apply(service1)\n",
    "    # del data['shop_score_service']\n",
    "    print(data.service_map.value_counts())  # 视为好评，中评，差评\n",
    "    #\n",
    "    data['shop_score_description'] = data['shop_score_description'] * 5\n",
    "    data = data[data['shop_score_description'] != -5]\n",
    "    data['de_map'] = data['shop_score_description'].apply(describe)\n",
    "    data['de_map'] = data['de_map'].apply(describe1)\n",
    "    # del data['shop_score_description']\n",
    "    print(data.de_map.value_counts())\n",
    "\n",
    "    data = data[data['shop_review_positive_rate'] != -1]\n",
    "    data['review_map'] = data['shop_review_positive_rate'].apply(review)\n",
    "    data['review_map'] = data['review_map'].apply(review1)\n",
    "    print(data.review_map.value_counts())\n",
    "\n",
    "    data['normal_shop'] = data.apply(\n",
    "        lambda x: 1 if (x.deliver_map == 3) & (x.service_map == 3) & (x.de_map == 3) & (x.review_map == 3) else 0,\n",
    "        axis=1)\n",
    "    del data['de_map']\n",
    "    del data['service_map']\n",
    "    del data['deliver_map']\n",
    "    del data['review_map']\n",
    "    return data\n",
    "\n",
    "\n",
    "def isPredict(df):\n",
    "\n",
    "    DF2 = df[[\n",
    "        'instance_id', 'predict_category_property', 'item_category_list',\n",
    "        'item_property_list'\n",
    "    ]]\n",
    "    data = []\n",
    "    for index, row in df.iterrows():\n",
    "        categorySet = set(row['item_category_list'].split(';'))\n",
    "        propertySet = set(row['item_property_list'].split(';'))\n",
    "        predicts = row['predict_category_property'].split(';')\n",
    "\n",
    "        preCate = []\n",
    "        prePro = []\n",
    "        for x in predicts:\n",
    "            try:\n",
    "                tmp = x.split(':')\n",
    "                preCate.append(tmp[0])\n",
    "                if tmp[1] != '-1':\n",
    "                    prePro.append(tmp[1])\n",
    "            except:\n",
    "                print(index, x, row)\n",
    "\n",
    "        isCategory = len(list(categorySet.intersection(set(preCate))))\n",
    "        isProperty = len(list(propertySet.intersection(set(prePro))))\n",
    "\n",
    "        data.append([row['instance_id'], isCategory, isProperty])\n",
    "\n",
    "    data = pd.DataFrame(\n",
    "        data, columns=['instance_id', 'isCategory', 'isProperty'])\n",
    "    data = pd.merge(df, data, on=['instance_id'], how='left')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def slide_cnt(data):\n",
    "    # item_cnt = data.groupby(by='item_id').count()['instance_id'].to_dict()\n",
    "    # data['item_cnt'] = data['item_id'].apply(lambda x: item_cnt[x])\n",
    "    # user_cnt = data.groupby(by='user_id').count()['instance_id'].to_dict()\n",
    "    # data['user_cnt'] = data['user_id'].apply(lambda x: user_cnt[x])\n",
    "    # shop_cnt = data.groupby(by='shop_id').count()['instance_id'].to_dict()\n",
    "    # data['shop_cnt'] = data['shop_id'].apply(lambda x: shop_cnt[x])\n",
    "\n",
    "    print('当前日期前一天的cnt')\n",
    "    for d in range(19, 26):  # 18到24号\n",
    "        df1 = data[data['day'] == d - 1]\n",
    "        df2 = data[data['day'] == d]  # 19到25号\n",
    "        user_cnt = df1.groupby(by='user_id').count()['instance_id'].to_dict()\n",
    "        item_cnt = df1.groupby(by='item_id').count()['instance_id'].to_dict()\n",
    "        shop_cnt = df1.groupby(by='shop_id').count()['instance_id'].to_dict()\n",
    "        item_brand_cnt = df1.groupby(\n",
    "            by='item_brand_id').count()['instance_id'].to_dict()\n",
    "        item_city_cnt = df1.groupby(\n",
    "            by='item_city_id').count()['instance_id'].to_dict()\n",
    "\n",
    "        df2['user_cnt1'] = df2['user_id'].apply(lambda x: user_cnt.get(x, 0))\n",
    "        df2['item_cnt1'] = df2['item_id'].apply(lambda x: item_cnt.get(x, 0))\n",
    "        df2['shop_cnt1'] = df2['shop_id'].apply(lambda x: shop_cnt.get(x, 0))\n",
    "        df2['item_brand_cnt1'] = df2['item_brand_id'].apply(\n",
    "            lambda x: item_brand_cnt.get(x, 0))\n",
    "        df2['item_city_cnt1'] = df2['item_city_id'].apply(\n",
    "            lambda x: item_city_cnt.get(x, 0))\n",
    "\n",
    "        df2 = df2[[\n",
    "            'user_cnt1', 'item_cnt1', 'shop_cnt1', 'item_brand_cnt1',\n",
    "            'item_city_cnt1', 'instance_id'\n",
    "        ]]\n",
    "        if d == 19:\n",
    "            Df2 = df2\n",
    "        else:\n",
    "            Df2 = pd.concat([df2, Df2])\n",
    "    data = pd.merge(data, Df2, on=['instance_id'], how='left')\n",
    "\n",
    "    print('当前日期之前的cnt')\n",
    "    for d in range(19, 26):\n",
    "        # 19到25，25是test\n",
    "        df1 = data[data['day'] < d]\n",
    "        df2 = data[data['day'] == d]\n",
    "        user_cnt = df1.groupby(by='user_id').count()['instance_id'].to_dict()\n",
    "        item_cnt = df1.groupby(by='item_id').count()['instance_id'].to_dict()\n",
    "        shop_cnt = df1.groupby(by='shop_id').count()['instance_id'].to_dict()\n",
    "        shop_cnt = df1.groupby(by='shop_id').count()['instance_id'].to_dict()\n",
    "        item_brand_cnt = df1.groupby(\n",
    "            by='item_brand_id').count()['instance_id'].to_dict()\n",
    "        item_city_cnt = df1.groupby(\n",
    "            by='item_city_id').count()['instance_id'].to_dict()\n",
    "\n",
    "        df2['user_cntx'] = df2['user_id'].apply(lambda x: user_cnt.get(x, 0))\n",
    "        df2['item_cntx'] = df2['item_id'].apply(lambda x: item_cnt.get(x, 0))\n",
    "        df2['shop_cntx'] = df2['shop_id'].apply(lambda x: shop_cnt.get(x, 0))\n",
    "        df2['item_brand_cntx'] = df2['item_brand_id'].apply(\n",
    "            lambda x: item_brand_cnt.get(x, 0))\n",
    "        df2['item_city_cntx'] = df2['item_city_id'].apply(\n",
    "            lambda x: item_city_cnt.get(x, 0))\n",
    "        df2 = df2[[\n",
    "            'user_cntx', 'item_cntx', 'shop_cntx', 'item_brand_cntx',\n",
    "            'item_city_cntx', 'instance_id'\n",
    "        ]]\n",
    "        if d == 19:\n",
    "            Df2 = df2\n",
    "        else:\n",
    "            Df2 = pd.concat([df2, Df2])\n",
    "    data = pd.merge(data, Df2, on=['instance_id'], how='left')\n",
    "\n",
    "    #print(\"前一个小时的统计量\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def join(data):\n",
    "    for col in [\n",
    "            'item_sales_level', 'item_price_level', 'item_collected_level',\n",
    "            'user_gender_id', 'user_age_level', 'user_occupation_id',\n",
    "            'user_star_level', 'shop_review_num_level', 'shop_star_level',\n",
    "            'hour', 'item_category_list1'\n",
    "    ]:\n",
    "        data[col] = data[col].apply(lambda x: 0 if x == -1 else x)\n",
    "\n",
    "    for col in [\n",
    "            'item_sales_level', 'item_price_level', 'item_collected_level',\n",
    "            'user_gender_id', 'user_age_level', 'user_occupation_id',\n",
    "            'user_star_level', 'shop_review_num_level', 'shop_star_level',\n",
    "            'hour', 'item_category_list1'\n",
    "    ]:\n",
    "        data[col] = data[col].astype(str)\n",
    "\n",
    "    print('item两两组合')\n",
    "    data = data.assign(A=data.item_sales_level + data.item_price_level)\n",
    "    data = data.assign(B=data.item_sales_level + data.item_collected_level)\n",
    "    data = data.assign(C=data.item_price_level + data.item_collected_level)\n",
    "\n",
    "    print('user两两组合')\n",
    "    data = data.assign(D=data.user_gender_id + data.item_price_level)\n",
    "    data = data.assign(E=data.user_gender_id + data.user_occupation_id)\n",
    "    data = data.assign(F=data.user_gender_id + data.user_star_level)\n",
    "    data = data.assign(G=data.user_gender_id + data.hour)\n",
    "    data = data.assign(H=data.user_occupation_id + data.hour)\n",
    "\n",
    "    print('shop两两组合')\n",
    "    data = data.assign(I=data.shop_review_num_level + data.shop_star_level)\n",
    "\n",
    "    print('shop-item两两组合')\n",
    "    data = data.assign(J=data.shop_review_num_level + data.item_sales_level)\n",
    "    data = data.assign(K=data.shop_review_num_level + data.item_price_level)\n",
    "    data = data.assign(\n",
    "        L=data.shop_review_num_level + data.item_collected_level)\n",
    "    data = data.assign(M=data.shop_star_level + data.item_sales_level)\n",
    "    data = data.assign(N=data.shop_star_level + data.item_price_level)\n",
    "    data = data.assign(O=data.shop_star_level + data.item_collected_level)\n",
    "\n",
    "    print('类别时间两两组合')\n",
    "    data = data.assign(P=data.item_category_list1 + data.hour)\n",
    "\n",
    "    for col in [\n",
    "            'item_sales_level', 'item_price_level', 'item_collected_level',\n",
    "            'user_gender_id', 'user_age_level', 'user_occupation_id',\n",
    "            'user_star_level', 'shop_review_num_level', 'shop_star_level',\n",
    "            'hour', 'item_category_list1', 'A', 'B', 'C', 'D', 'E', 'F', 'G',\n",
    "            'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'\n",
    "    ]:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def item(data):\n",
    "    print('一个item有多少brand,price salse collected level……')\n",
    "\n",
    "    itemcnt = data.groupby(\n",
    "        ['item_id'], as_index=False)['instance_id'].agg({\n",
    "            'item_cnt': 'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['item_id'], how='left')\n",
    "\n",
    "    for col in [\n",
    "            'item_brand_id', 'item_city_id', 'item_price_level',\n",
    "            'item_sales_level', 'item_collected_level', 'item_pv_level'\n",
    "    ]:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'item_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_item_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, itemcnt, on=[col, 'item_id'], how='left')\n",
    "        data[str(col) + '_item_prob'] = data[str(col)\n",
    "                                             + '_item_cnt'] / data['item_cnt']\n",
    "    del data['item_cnt']\n",
    "\n",
    "    print('一个brand有多少price salse collected level……')\n",
    "\n",
    "    itemcnt = data.groupby(\n",
    "        ['item_brand_id'], as_index=False)['instance_id'].agg({\n",
    "            'item_brand_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['item_brand_id'], how='left')\n",
    "\n",
    "    for col in [\n",
    "            'item_city_id', 'item_price_level', 'item_sales_level',\n",
    "            'item_collected_level', 'item_pv_level'\n",
    "    ]:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'item_brand_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_brand_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, itemcnt, on=[col, 'item_brand_id'], how='left')\n",
    "        data[str(col) + '_brand_prob'] = data[str(col) + '_brand_cnt'] / data[\n",
    "            'item_brand_cnt']\n",
    "    del data['item_brand_cnt']\n",
    "\n",
    "    print(\n",
    "        '一个city有多少item_price_level，item_sales_level，item_collected_level，item_pv_level'\n",
    "    )\n",
    "\n",
    "    itemcnt = data.groupby(\n",
    "        ['item_city_id'], as_index=False)['instance_id'].agg({\n",
    "            'item_city_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['item_city_id'], how='left')\n",
    "    for col in [\n",
    "            'item_price_level', 'item_sales_level', 'item_collected_level',\n",
    "            'item_pv_level'\n",
    "    ]:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'item_city_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_city_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, itemcnt, on=[col, 'item_city_id'], how='left')\n",
    "        data[str(col) + '_city_prob'] = data[str(col) + '_city_cnt'] / data[\n",
    "            'item_city_cnt']\n",
    "    del data['item_city_cnt']\n",
    "\n",
    "    print('一个price有多少item_sales_level，item_collected_level，item_pv_level')\n",
    "\n",
    "    itemcnt = data.groupby(\n",
    "        ['item_price_level'], as_index=False)['instance_id'].agg({\n",
    "            'item_price_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['item_price_level'], how='left')\n",
    "    for col in ['item_sales_level', 'item_collected_level', 'item_pv_level']:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'item_city_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_price_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, itemcnt, on=[col, 'item_city_id'], how='left')\n",
    "        data[str(col) + '_price_prob'] = data[str(col) + '_price_cnt'] / data[\n",
    "            'item_price_cnt']\n",
    "    del data['item_price_cnt']\n",
    "\n",
    "    print('一个item_sales_level有多少item_collected_level，item_pv_level')\n",
    "\n",
    "    itemcnt = data.groupby(\n",
    "        ['item_sales_level'], as_index=False)['instance_id'].agg({\n",
    "            'item_salse_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['item_sales_level'], how='left')\n",
    "    for col in ['item_collected_level', 'item_pv_level']:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'item_sales_level'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_salse_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, itemcnt, on=[col, 'item_sales_level'], how='left')\n",
    "        data[str(col) + '_salse_prob'] = data[str(col) + '_salse_cnt'] / data[\n",
    "            'item_salse_cnt']\n",
    "    del data['item_salse_cnt']\n",
    "\n",
    "    print('一个item_collected_level有多少item_pv_level')\n",
    "\n",
    "    itemcnt = data.groupby(\n",
    "        ['item_collected_level'], as_index=False)['instance_id'].agg({\n",
    "            'item_coll_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['item_collected_level'], how='left')\n",
    "    for col in ['item_pv_level']:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'item_collected_level'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_coll_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, itemcnt, on=[col, 'item_collected_level'], how='left')\n",
    "        data[str(col) + '_coll_prob'] = data[str(col) + '_coll_cnt'] / data[\n",
    "            'item_coll_cnt']\n",
    "    del data['item_coll_cnt']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def user(data):\n",
    "    print('用户有多少性别')\n",
    "    itemcnt = data.groupby(\n",
    "        ['user_id'], as_index=False)['instance_id'].agg({\n",
    "            'user_cnt': 'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['user_id'], how='left')\n",
    "\n",
    "    for col in [\n",
    "            'user_gender_id', 'user_age_level', 'user_occupation_id',\n",
    "            'user_star_level'\n",
    "    ]:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'user_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, itemcnt, on=[col, 'user_id'], how='left')\n",
    "        data[str(col) + '_user_prob'] = data[str(col)\n",
    "                                             + '_user_cnt'] / data['user_cnt']\n",
    "    del data['user_cnt']\n",
    "\n",
    "    print('性别的年龄段，职业有多少')\n",
    "    itemcnt = data.groupby(\n",
    "        ['user_gender_id'], as_index=False)['instance_id'].agg({\n",
    "            'user_gender_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['user_gender_id'], how='left')\n",
    "\n",
    "    for col in ['user_age_level', 'user_occupation_id', 'user_star_level']:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'user_gender_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_gender_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, itemcnt, on=[col, 'user_gender_id'], how='left')\n",
    "        data[str(col) + '_user_gender_prob'] = data[\n",
    "            str(col) + '_user_gender_cnt'] / data['user_gender_cnt']\n",
    "    del data['user_gender_cnt']\n",
    "\n",
    "    print('user_age_level对应的user_occupation_id，user_star_level')\n",
    "    itemcnt = data.groupby(\n",
    "        ['user_age_level'], as_index=False)['instance_id'].agg({\n",
    "            'user_age_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['user_age_level'], how='left')\n",
    "\n",
    "    for col in ['user_occupation_id', 'user_star_level']:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'user_age_level'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_age_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, itemcnt, on=[col, 'user_age_level'], how='left')\n",
    "        data[str(col) + '_user_age_prob'] = data[\n",
    "            str(col) + '_user_age_cnt'] / data['user_age_cnt']\n",
    "    del data['user_age_cnt']\n",
    "\n",
    "    print('user_occupation_id对应的user_star_level')\n",
    "    itemcnt = data.groupby(\n",
    "        ['user_occupation_id'], as_index=False)['instance_id'].agg({\n",
    "            'user_occ_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['user_occupation_id'], how='left')\n",
    "    for col in ['user_star_level']:\n",
    "        itemcnt = data.groupby(\n",
    "            [col, 'user_occupation_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_occ_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, itemcnt, on=[col, 'user_occupation_id'], how='left')\n",
    "        data[str(col) + '_user_occ_prob'] = data[\n",
    "            str(col) + '_user_occ_cnt'] / data['user_occ_cnt']\n",
    "    del data['user_occ_cnt']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def user_item(data):\n",
    "    itemcnt = data.groupby(\n",
    "        ['user_id'], as_index=False)['instance_id'].agg({\n",
    "            'user_cnt': 'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['user_id'], how='left')\n",
    "    print('一个user有多少item_id,item_brand_id……')\n",
    "    for col in [\n",
    "            'item_id', 'item_brand_id', 'item_city_id', 'item_price_level',\n",
    "            'item_sales_level', 'item_collected_level', 'item_pv_level'\n",
    "    ]:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'user_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, item_shop_cnt, on=[col, 'user_id'], how='left')\n",
    "        data[str(col) + '_user_prob'] = data[str(col)\n",
    "                                             + '_user_cnt'] / data['user_cnt']\n",
    "\n",
    "    print('一个user_gender有多少item_id,item_brand_id……')\n",
    "    itemcnt = data.groupby(\n",
    "        ['user_gender_id'], as_index=False)['instance_id'].agg({\n",
    "            'user_gender_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['user_gender_id'], how='left')\n",
    "    for col in [\n",
    "            'item_id', 'item_brand_id', 'item_city_id', 'item_price_level',\n",
    "            'item_sales_level', 'item_collected_level', 'item_pv_level'\n",
    "    ]:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'user_gender_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_gender_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, item_shop_cnt, on=[col, 'user_gender_id'], how='left')\n",
    "        data[str(col) + '_user_gender_prob'] = data[\n",
    "            str(col) + '_user_gender_cnt'] / data['user_gender_cnt']\n",
    "\n",
    "    print('一个user_age_level有多少item_id,item_brand_id……')\n",
    "    itemcnt = data.groupby(\n",
    "        ['user_age_level'], as_index=False)['instance_id'].agg({\n",
    "            'user_age_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['user_age_level'], how='left')\n",
    "    for col in [\n",
    "            'item_id', 'item_brand_id', 'item_city_id', 'item_price_level',\n",
    "            'item_sales_level', 'item_collected_level', 'item_pv_level'\n",
    "    ]:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'user_age_level'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_age_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, item_shop_cnt, on=[col, 'user_age_level'], how='left')\n",
    "        data[str(col) + '_user_age_prob'] = data[\n",
    "            str(col) + '_user_age_cnt'] / data['user_age_cnt']\n",
    "\n",
    "    print('一个user_occupation_id有多少item_id,item_brand_id…')\n",
    "    itemcnt = data.groupby(\n",
    "        ['user_occupation_id'], as_index=False)['instance_id'].agg({\n",
    "            'user_occ_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['user_occupation_id'], how='left')\n",
    "    for col in [\n",
    "            'item_id', 'item_brand_id', 'item_city_id', 'item_price_level',\n",
    "            'item_sales_level', 'item_collected_level', 'item_pv_level'\n",
    "    ]:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'user_occupation_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_occ_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, item_shop_cnt, on=[col, 'user_occupation_id'], how='left')\n",
    "        data[str(col) + '_user_occ_prob'] = data[\n",
    "            str(col) + '_user_occ_cnt'] / data['user_occ_cnt']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def user_shop(data):\n",
    "    print('一个user有多少shop_id,shop_review_num_level……')\n",
    "\n",
    "    for col in ['shop_id', 'shop_review_num_level', 'shop_star_level']:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'user_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, item_shop_cnt, on=[col, 'user_id'], how='left')\n",
    "        data[str(col) + '_user_prob'] = data[str(col)\n",
    "                                             + '_user_cnt'] / data['user_cnt']\n",
    "    del data['user_cnt']\n",
    "\n",
    "    print('一个user_gender有多少shop_id,shop_review_num_level……')\n",
    "    for col in ['shop_id', 'shop_review_num_level', 'shop_star_level']:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'user_gender_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_gender_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, item_shop_cnt, on=[col, 'user_gender_id'], how='left')\n",
    "        data[str(col) + '_user_gender_prob'] = data[\n",
    "            str(col) + '_user_gender_cnt'] / data['user_gender_cnt']\n",
    "    del data['user_gender_cnt']\n",
    "\n",
    "    print('一个user_age_level有多少shop_id,shop_review_num_level……')\n",
    "    for col in ['shop_id', 'shop_review_num_level', 'shop_star_level']:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'user_age_level'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_age_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, item_shop_cnt, on=[col, 'user_age_level'], how='left')\n",
    "        data[str(col) + '_user_age_prob'] = data[\n",
    "            str(col) + '_user_age_cnt'] / data['user_age_cnt']\n",
    "    del data['user_age_cnt']\n",
    "\n",
    "    print('一个user_occupation_id有多少shop_id,shop_review_num_level……')\n",
    "    for col in ['shop_id', 'shop_review_num_level', 'shop_star_level']:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'user_occupation_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_user_occ_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, item_shop_cnt, on=[col, 'user_occupation_id'], how='left')\n",
    "        data[str(col) + '_user_occ_prob'] = data[\n",
    "            str(col) + '_user_occ_cnt'] / data['user_occ_cnt']\n",
    "    del data['user_occ_cnt']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def shop_item(data):\n",
    "    print('一个shop有多少item_id,item_brand_id,item_city_id,item_price_level……')\n",
    "    itemcnt = data.groupby(\n",
    "        ['shop_id'], as_index=False)['instance_id'].agg({\n",
    "            'shop_cnt': 'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['shop_id'], how='left')\n",
    "    for col in [\n",
    "            'item_id', 'item_brand_id', 'item_city_id', 'item_price_level',\n",
    "            'item_sales_level', 'item_collected_level', 'item_pv_level'\n",
    "    ]:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'shop_id'], as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_shop_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(data, item_shop_cnt, on=[col, 'shop_id'], how='left')\n",
    "        data[str(col) + '_shop_prob'] = data[str(col)\n",
    "                                             + '_shop_cnt'] / data['shop_cnt']\n",
    "    del data['shop_cnt']\n",
    "\n",
    "    print(\n",
    "        '一个shop_review_num_level有多少item_id,item_brand_id,item_city_id,item_price_level……'\n",
    "    )\n",
    "    itemcnt = data.groupby(\n",
    "        ['shop_review_num_level'], as_index=False)['instance_id'].agg({\n",
    "            'shop_rev_cnt':\n",
    "            'count'\n",
    "        })\n",
    "    data = pd.merge(data, itemcnt, on=['shop_review_num_level'], how='left')\n",
    "    for col in [\n",
    "            'item_id', 'item_brand_id', 'item_city_id', 'item_price_level',\n",
    "            'item_sales_level', 'item_collected_level', 'item_pv_level'\n",
    "    ]:\n",
    "        item_shop_cnt = data.groupby(\n",
    "            [col, 'shop_review_num_level'],\n",
    "            as_index=False)['instance_id'].agg({\n",
    "                str(col) + '_shop_rev_cnt':\n",
    "                'count'\n",
    "            })\n",
    "        data = pd.merge(\n",
    "            data, item_shop_cnt, on=[col, 'shop_review_num_level'], how='left')\n",
    "        data[str(col) + '_shop_rev_prob'] = data[\n",
    "            str(col) + '_shop_rev_cnt'] / data['shop_rev_cnt']\n",
    "    del data['shop_rev_cnt']\n",
    "\n",
    "    # print('一个shop_star_level有多少item_id,item_brand_id,item_city_id,item_price_level……')\n",
    "    # itemcnt = data.groupby(['shop_star_level'], as_index=False)['instance_id'].agg({'shop_star_cnt': 'count'})\n",
    "    # data = pd.merge(data, itemcnt, on=['shop_star_level'], how='left')\n",
    "    # for col in ['item_id',\n",
    "    #             'item_brand_id', 'item_city_id', 'item_price_level',\n",
    "    #             'item_sales_level', 'item_collected_level', 'item_pv_level']:\n",
    "    #     item_shop_cnt = data.groupby([col, 'shop_star_level'], as_index=False)['instance_id'].agg({str(col) + '_shop_star_cnt': 'count'})\n",
    "    #     data = pd.merge(data, item_shop_cnt, on=[col, 'shop_star_level'], how='left')\n",
    "    #     data[str(col) + '_shop_star_prob'] = data[str(col) + '_shop_star_cnt'] / data['shop_star_cnt']\n",
    "    # del data['shop_star_cnt']\n",
    "    return data\n",
    "\n",
    "\n",
    "def lgbCV_online(train, test):\n",
    "    col = [\n",
    "        c for c in train if c not in [\n",
    "            'is_trade', 'item_category_list', 'item_property_list',\n",
    "            'predict_category_property', 'instance_id', 'context_id',\n",
    "            'realtime', 'context_timestamp'\n",
    "        ]\n",
    "    ]\n",
    "    # cat = ['sale_price', 'gender_star', 'user_age_level', 'item_price_level', 'item_sales_level', 'sale_collect',\n",
    "    #        'price_collect', 'item_brand_id', 'user_star_level', 'item_id', 'shop_id',\n",
    "    #        'item_city_id', 'context_page_id', 'gender_age', 'shop_star_level', 'item_pv_level', 'user_occupation_id',\n",
    "    #        'day', 'gender_occ', 'user_gender_id']\n",
    "    X = train[col]\n",
    "    y = train['is_trade'].values\n",
    "    X_tes = test[col]\n",
    "    y_tes = test['is_trade'].values\n",
    "    print('Training LGBM model...')\n",
    "    lgb0 = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        # metric='binary_error',\n",
    "        num_leaves=35,\n",
    "        depth=8,\n",
    "        learning_rate=0.005,\n",
    "        seed=2018,\n",
    "        colsample_bytree=0.8,\n",
    "        # min_child_samples=8,\n",
    "        subsample=0.9,\n",
    "        n_estimators=20000)\n",
    "    lgb_model = lgb0.fit(\n",
    "        X, y, eval_set=[(X_tes, y_tes)], early_stopping_rounds=200)\n",
    "    best_iter = lgb_model.best_iteration_\n",
    "\n",
    "    #print(get_leaf_output(tree_id, leaf_id))\n",
    "    '''\n",
    "    predictors = [i for i in X.columns]\n",
    "    feat_imp = pd.Series(lgb_model.feature_importance(), predictors).sort_values(ascending=False)\n",
    "    print(feat_imp)\n",
    "    print(feat_imp.shape)\n",
    "    # pred= lgb_model.predict(test[col])\n",
    "    '''\n",
    "    pred = lgb_model.predict_proba(test[col])[:, 1]\n",
    "    test['pred'] = pred\n",
    "    test['index'] = range(len(test))\n",
    "    # print(test[['is_trade','pred']])\n",
    "    print('误差 ', log_loss(test['is_trade'], test['pred']))\n",
    "\n",
    "    # +lr\n",
    "    # 编码原有特征\n",
    "    X_train_leaves = lgb0.apply(X)\n",
    "    X_test_leaves = lgb0.apply(X_tes)\n",
    "\n",
    "    # 对所有特征进行ont-hot编码\n",
    "    (train_rows, cols) = X_train_leaves.shape\n",
    "\n",
    "    gbdtenc = OneHotEncoder()\n",
    "    X_trans = gbdtenc.fit_transform(\n",
    "        np.concatenate((X_train_leaves, X_test_leaves), axis=0))\n",
    "\n",
    "    # 定义LR模型\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    # lr对gbdt特征编码后的样本模型训练\n",
    "    lr.fit(X_trans[:train_rows, :], y)\n",
    "\n",
    "    # 预测及AUC评测\n",
    "    y_pred_gbdtlr = lr.predict_proba(X_trans[train_rows:, :])[:, 1]\n",
    "    #     gbdt_lr_test_log_loss = log_loss(y_tes, y_pred_gbdtlr)\n",
    "    #     print('基于GBDT特征编码后的LR log_loss: %.5f' % gbdt_lr_test_log_loss)\n",
    "\n",
    "    return best_iter, y_tes, y_pred_gbdtlr\n",
    "\n",
    "\n",
    "def sub_online(train, test, best_iter, path):\n",
    "    col = [\n",
    "        c for c in train if c not in [\n",
    "            'is_trade', 'item_category_list', 'item_property_list',\n",
    "            'predict_category_property', 'instance_id', 'context_id',\n",
    "            'realtime', 'context_timestamp'\n",
    "        ]\n",
    "    ]\n",
    "    X = train[col]\n",
    "    y = train['is_trade'].values\n",
    "    print('Training LGBM model...')\n",
    "    lgb0 = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        # metric='binary_error',\n",
    "        num_leaves=35,\n",
    "        depth=8,\n",
    "        learning_rate=0.05,\n",
    "        seed=2018,\n",
    "        colsample_bytree=0.8,\n",
    "        # min_child_samples=8,\n",
    "        subsample=0.9,\n",
    "        n_estimators=best_iter)\n",
    "    lgb_model = lgb0.fit(X, y)\n",
    "\n",
    "    # pred= lgb_model.predict(test[col])\n",
    "    pred = lgb_model.predict_proba(test[col])[:, 1]\n",
    "    test['predicted_score'] = pred\n",
    "    sub1 = test[['instance_id', 'predicted_score']]\n",
    "    sub = pd.read_csv(path + \"round1_ijcai_18_test_a_20180301.txt\", sep=\"\\s+\")\n",
    "    sub = pd.merge(sub, sub1, on=['instance_id'], how='left')\n",
    "    sub = sub.fillna(0)\n",
    "    return sub[['instance_id', 'predicted_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T10:38:58.720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make feature\n",
      "--------------------------item---------------------------------\n",
      "--------------------------user---------------------------------\n",
      "user 0,1 feature\n",
      "--------------------context------------------------------------------\n",
      "context 0,1 feature\n",
      "-------------------------shop------------------------\n",
      "3    493224\n",
      "2      3146\n",
      "1        25\n",
      "Name: deliver_map, dtype: int64\n",
      "3    490039\n",
      "2      6243\n",
      "1       113\n",
      "Name: service_map, dtype: int64\n",
      "3    394629\n",
      "2     99788\n",
      "1      1978\n",
      "Name: de_map, dtype: int64\n",
      "3    356965\n",
      "2    138783\n",
      "1       647\n",
      "Name: review_map, dtype: int64\n",
      "当前日期前一天的cnt\n",
      "当前日期之前的cnt\n",
      "item两两组合\n",
      "user两两组合\n",
      "shop两两组合\n",
      "shop-item两两组合\n",
      "类别时间两两组合\n",
      "-------------------------全局统计特征------------------------\n",
      "一个item有多少brand,price salse collected level……\n",
      "一个brand有多少price salse collected level……\n",
      "一个city有多少item_price_level，item_sales_level，item_collected_level，item_pv_level\n",
      "一个price有多少item_sales_level，item_collected_level，item_pv_level\n",
      "一个item_sales_level有多少item_collected_level，item_pv_level\n",
      "一个item_collected_level有多少item_pv_level\n",
      "用户有多少性别\n",
      "性别的年龄段，职业有多少\n",
      "user_age_level对应的user_occupation_id，user_star_level\n",
      "user_occupation_id对应的user_star_level\n",
      "一个user有多少item_id,item_brand_id……\n",
      "一个user_gender有多少item_id,item_brand_id……\n",
      "一个user_age_level有多少item_id,item_brand_id……\n",
      "一个user_occupation_id有多少item_id,item_brand_id…\n",
      "一个user有多少shop_id,shop_review_num_level……\n",
      "一个user_gender有多少shop_id,shop_review_num_level……\n",
      "一个user_age_level有多少shop_id,shop_review_num_level……\n",
      "一个user_occupation_id有多少shop_id,shop_review_num_level……\n",
      "一个shop有多少item_id,item_brand_id,item_city_id,item_price_level……\n"
     ]
    }
   ],
   "source": [
    "path = '../Data/'\n",
    "train = pd.read_csv(path + 'round1_ijcai_18_train_20180301.txt', sep=\"\\s+\")\n",
    "test = pd.read_csv(path + 'round1_ijcai_18_test_a_20180301.txt', sep=\"\\s+\")\n",
    "data = pd.concat([train, test])\n",
    "data = data.drop_duplicates(subset='instance_id')  # 把instance id去重\n",
    "print('make feature')\n",
    "data = base_process(data)\n",
    "data = timeMap(data)\n",
    "data = shop_box(data)\n",
    "data = slide_cnt(data)\n",
    "#data = isPredict(data)\n",
    "data = join(data)\n",
    "print('-------------------------全局统计特征------------------------')\n",
    "data = item(data)\n",
    "data = user(data)\n",
    "data = user_item(data)\n",
    "data = user_shop(data)\n",
    "data = shop_item(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T10:38:58.725Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-------------------------线下---------------------------\")\n",
    "# 0~7小时\n",
    "train1 = data[(data['day'] >= 18) & (data['day'] <= 23) &\n",
    "              (data['hour_map'] == 1)]\n",
    "test1 = data[(data['day'] == 24) & (data['hour_map'] == 1)]\n",
    "best_iter, y_tes1, y_pred_gbdtlr1 = lgbCV_online(train1, test1)\n",
    "joblib.dump(best_iter, 'gdbt_lr_0to7.model')\n",
    "print(\"0~7小时模型完成\")\n",
    "# 8~15小时\n",
    "train2 = data[(data['day'] >= 18) & (data['day'] <= 23) &\n",
    "              (data['hour_map'] == 2)]\n",
    "test2 = data[(data['day'] == 24) & (data['hour_map'] == 2)]\n",
    "best_iter, y_tes2, y_pred_gbdtlr2 = lgbCV_online(train2, test2)\n",
    "joblib.dump(best_iter, 'gdbt_lr_8to15.model')\n",
    "print(\"8~15小时模型完成\")\n",
    "# 15~23小时\n",
    "train3 = data[(data['day'] >= 18) & (data['day'] <= 23) &\n",
    "              (data['hour_map'] == 3)]\n",
    "test3 = data[(data['day'] == 24) & (data['hour_map'] == 3)]\n",
    "best_iter, y_tes3, y_pred_gbdtlr3 = lgbCV_online(train3, test3)\n",
    "joblib.dump(best_iter, 'gdbt_lr_16to23.model')\n",
    "print(\"16~23小时模型完成\")\n",
    "\n",
    "y_tes = pd.concat([y_tes1, y_tes2, y_tes3], ignore_index=True)\n",
    "y_pred_gbdtlr = pd.concat(\n",
    "    [y_pred_gbdtlr1, y_pred_gbdtlr2, y_pred_gbdtlr3], ignore_index=True)\n",
    "\n",
    "gbdt_lr_test_log_loss = log_loss(y_tes, y_pred_gbdtlr)\n",
    "print('基于GBDT特征编码后的LR log_loss: %.5f' % gbdt_lr_test_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T10:38:58.727Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"-------------------线上----------------------\")\n",
    "train1 = data[data.is_trade.notnull() & (data['hour_map'] == 1)]\n",
    "test1 = data[data.is_trade.isnull() & (data['hour_map'] == 1)]\n",
    "gdbt_lr = joblib.load('gdbt_lr_0to7.model')\n",
    "res1 = sub_online(train1, test1, gdbt_lr, path)\n",
    "\n",
    "train2 = data[data.is_trade.notnull() & (data['hour_map'] == 2)]\n",
    "test2 = data[data.is_trade.isnull() & (data['hour_map'] == 2)]\n",
    "gdbt_lr = joblib.load('gdbt_lr_8to15.model')\n",
    "res2 = sub_online(train2, test2, gdbt_lr, path)\n",
    "\n",
    "train3 = data[data.is_trade.notnull() & (data['hour_map'] == 3)]\n",
    "test3 = data[data.is_trade.isnull() & (data['hour_map'] == 3)]\n",
    "gdbt_lr = joblib.load('gdbt_lr_16to23.model')\n",
    "res3 = sub_online(train3, test3, gdbt_lr, path)\n",
    "\n",
    "res = pd.concat([res1, res2, res3], ignore_index=True)\n",
    "res.to_csv('../result_0406.txt',sep=\" \",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
